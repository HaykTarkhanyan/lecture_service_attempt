\documentclass[a4paper]{article}

\input{../../style/preamble_ex_summer_school.tex}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-trees.tex}
\input{../../latex-math/ml-interpretable.tex}

\usepackage{hyperref}
\usepackage{enumitem}

\begin{document}

\kopf{4}

%\input{ex_tex/ex_inclass.tex}

\aufgabe{Quiz}{
\begin{enumerate}
    %\item What is the prediction target in contrast to the prediction?
    %\item What is the model's mechanism in contrast to the data generating process (DGP)?
    \item Yes or No: Shapley values and SHAP values are different names for the same concept.
    \item What are SHAP value functions $v$ in contrast to SHAP values $\phi$?
    %\item What is the difference between marginal and conditional SHAP?
    %\item What is the difference between kernel SHAP and tree SHAP?
    \item Does the dependence structure in the DGP influence the SHAP result?
    \item In what sense are local, post-hoc interpretation techniques helpful in auditing AI systems?
    \item In which way does the SHAP feature importance differ from the permutation feature importance?
    \item In which way does the SHAP dependency plot differ from the ICE plot?
    %\item What is the motivation of LIME?
    %\item Both SHAP and LIME can be seen as local linear approximations. Name differences between SHAP and LIME.
    %\item Name hyperparameters for LIME. What do they steer?
\end{enumerate}
}

\dlz

\aufgabe{Application}{
Make yourself familiar with the method Shapley in the iml package.
Answer the following questions for your chosen dataset
\begin{enumerate}
\item Choose 3-4 observations of your dataset which might be worth to explain via Shapley values. Explain how you chose these observations.
\item Calculate and visualize the Shapley values for these observations and interpret your results. 
\item Sample 100 observations from your dataset at hand and calculate the Shapley values for these observations
\begin{itemize}
\item Calculate the Shapley feature importance for your sample. How does it differ from the PFI?
\item Create a Shapley dependency plot for the 6 features you have chosen in the feature effects exercise and compare your plots with the PDPs.
\end{itemize}
\end{enumerate}




\end{document}
 