\documentclass[a4paper]{article}

\input{../../style/preamble_ex_summer_school.tex}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-trees.tex}
\input{../../latex-math/ml-interpretable.tex}

\usepackage{hyperref}
\usepackage{enumitem}

\begin{document}

\kopf{4}

%\input{ex_tex/ex_inclass.tex}

\aufgabe{Quiz}{
\begin{enumerate}
    %\item What is the prediction target in contrast to the prediction? $\Rightarrow$ \textbf{The prediction target is the true target value that we observe, while the prediction is the predicted outcome of the ML model for our prediction target}
    %\item What is the model's mechanism in contrast to the data generating process (DGP)? $\Rightarrow$ \textbf{The model's mechanism is what the relationships between the features and the target variable that the ML has learned while the DGP are the true underlying relationships between the features and the true target variable.}
    \item Yes or No: Shapley values and SHAP values are different names for the same concept. $\Rightarrow$ \textbf{Yes.}
    \item What are SHAP value functions $v$ in contrast to SHAP values $\phi$? $\Rightarrow$ \textbf{Value functions determine the payout for one specific coaltion while SHAP values quantify the fair contribution of each player / feature on the total payout. In ML the value function is typically chosen to be the prediction function while the SHAP value is the fair contribution of a feature to the difference between the actual and the average prediction.}
    %\item What is the difference between marginal and conditional SHAP?
    %\item What is the difference between kernel SHAP and tree SHAP?
    \item Does the dependence structure in the DGP influence the SHAP result? $\Rightarrow$ \textbf{Yes, the dependence structure in the DGP can influence the SHAP result since we use marginal distributions for creating the artificial data points to compute the SHAP values, hence, it inherents the same drawbacks as the PDP and PFI.}
    %\item In what sense are local, post-hoc interpretation techniques helpful in auditing AI systems?
    \item In which way does the SHAP feature importance differ from the permutation feature importance? $\Rightarrow$ \textbf{The SHAP feature important is based on SHAP values which are prediction and not performance based as the PFI. Also SHAP values distribute interaction effects fairly among features by building different feature coaltions while PFI only considers the contribution of the feature of interest to the full model.}
    \item In which way does the SHAP dependency plot differ from the PDP? $\Rightarrow$ \textbf{The SHAP dependency plot shows the SHAP values of a feature of interest vs. the feature values of this feature of interest, while the PDP shows the average over the ICE curves (the average marginal effect) of the feature of interest vs. the the feature values of this feature of interest.}
    %\item What is the motivation of LIME?
    %\item Both SHAP and LIME can be seen as local linear approximations. Name differences between SHAP and LIME.
    %\item Name hyperparameters for LIME. What do they steer?
\end{enumerate}
}




\end{document}
 