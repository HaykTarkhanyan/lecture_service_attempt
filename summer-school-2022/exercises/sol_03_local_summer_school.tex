\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-trees.tex}
\input{../../latex-math/ml-interpretable.tex}

\usepackage{hyperref}
\usepackage{enumitem}

\begin{document}

\kopf{3}

%\input{ex_tex/ex_inclass.tex}

\aufgabe{Quiz}{

\begin{enumerate}
  \item Which of the following statement(s) about local surrogate models is/are correct?  
            \begin{enumerate}
                \item Surrogate models produced by LIME should have the same prediction as the model to be explained for the whole training dataset. \textcolor{blue}{Not correct, they should be faithful in the neighborhood of the point of interest, the closer a point is to the point of interest, the closer the prediction of the local surrogate model should be to the original prediction.}
                \item The choice of the sampling process and the definition of locality are important hyperparameters of LIME that have a large impact on the behavior of the method. \textcolor{blue}{Correct}
                \item LIME does not require any adaptions to be applicable to deep learning models for image data. \textcolor{blue}{Not correct, adaption to distance function is necessary} 
                \item LIME requires the surrogate model to use all available features - a selection of features is not allowed. \textcolor{blue}{Not correct, L0-regularized/LASSO model possible}
                \item If the kernel width for the exponential kernel is set to infinity, all observations receive a proximity measure/weight of $1$ independent of their distance to $\xv$. \textcolor{blue}{Correct}
          \end{enumerate}
  \item Which of the following statement(s) about counterfactual explanations is/are correct? 
        \begin{enumerate}
        \item In case of only two continuous features, we could directly read of counterfactuals from a surface plot. 
        \textcolor{blue}{Correct}
        \item Counterfactual explanations are not suitable for people without machine learning knowledge, because reasoning by "What if..." questions are not natural for human beings. \textcolor{blue}{Not correct, reasoning of human beings often in the form of counterfactuals.}
         \item Making use of domain-knowledge encoded in causal graphs, could help to receive more realistic counterfactuals. \textcolor{blue}{Correct}
        \end{enumerate}
\end{enumerate}
}




\end{document}
 